"""
Main orchestration script for Delhi fraud acquittal research
Coordinates scraping, analysis, and report generation
"""

import os
import sys
import logging
from datetime import datetime

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_dependencies():
    """Check if required packages are installed"""
    try:
        import requests
        import bs4
        logger.info("✓ All dependencies installed")
        return True
    except ImportError as e:
        logger.error(f"✗ Missing dependency: {e}")
        logger.info("Please run: pip install -r ../requirements.txt")
        return False


def run_scraper():
    """Run the Indian Kanoon scraper"""
    logger.info("="*70)
    logger.info("PHASE 1: WEB SCRAPING")
    logger.info("="*70)

    try:
        from indian_kanoon_scraper import main as scraper_main
        logger.info("Starting web scraper...")
        scraper_main()
        logger.info("✓ Scraping completed successfully")
        return True
    except Exception as e:
        logger.error(f"✗ Scraping failed: {e}")
        return False


def run_analysis():
    """Run the analysis on scraped data"""
    logger.info("\n" + "="*70)
    logger.info("PHASE 2: DATA ANALYSIS")
    logger.info("="*70)

    try:
        from analyze_judgments import JudgmentAnalyzer

        # Find the detailed cases file
        data_dir = '../data'
        cases_file = None

        for filename in os.listdir(data_dir):
            if 'detailed.json' in filename and 'partial' not in filename:
                cases_file = os.path.join(data_dir, filename)
                break

        if not cases_file:
            logger.error("✗ No detailed cases file found")
            return False

        logger.info(f"Analyzing cases from: {cases_file}")
        analyzer = JudgmentAnalyzer(cases_file)
        analysis, report = analyzer.save_analysis('delhi_fraud_acquittals_analysis')

        logger.info("✓ Analysis completed successfully")
        logger.info(f"\nAnalyzed {analysis['total_cases']} cases")
        logger.info(f"Average duration: {analysis['temporal_analysis']['average_duration_years']} years")

        return True
    except Exception as e:
        logger.error(f"✗ Analysis failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def generate_final_report():
    """Generate the final comprehensive research document"""
    logger.info("\n" + "="*70)
    logger.info("PHASE 3: FINAL REPORT GENERATION")
    logger.info("="*70)

    try:
        # The report is already generated by the analyzer
        report_file = '../data/delhi_fraud_acquittals_analysis.md'

        if os.path.exists(report_file):
            logger.info(f"✓ Final report available at: {report_file}")

            # Print summary
            with open(report_file, 'r', encoding='utf-8') as f:
                content = f.read()
                print("\n" + "="*70)
                print("RESEARCH SUMMARY")
                print("="*70)
                # Print first 2000 characters
                print(content[:2000])
                print("\n... (see full report in file)")

            return True
        else:
            logger.error("✗ Report file not found")
            return False

    except Exception as e:
        logger.error(f"✗ Report generation failed: {e}")
        return False


def main():
    """Main orchestration function"""
    print("\n" + "="*70)
    print("DELHI FRAUD ACQUITTAL CASES - COMPREHENSIVE RESEARCH")
    print("="*70)
    print(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*70 + "\n")

    # Check dependencies
    if not check_dependencies():
        sys.exit(1)

    # Phase 1: Scraping
    scraping_success = run_scraper()
    if not scraping_success:
        logger.warning("Scraping encountered issues. Check if data files exist to proceed with analysis.")

    # Phase 2: Analysis
    analysis_success = run_analysis()
    if not analysis_success:
        logger.error("Analysis failed. Cannot proceed to final report.")
        sys.exit(1)

    # Phase 3: Final Report
    report_success = generate_final_report()

    # Summary
    print("\n" + "="*70)
    print("RESEARCH PIPELINE COMPLETE")
    print("="*70)
    print(f"Scraping: {'✓ Success' if scraping_success else '✗ Failed/Skipped'}")
    print(f"Analysis: {'✓ Success' if analysis_success else '✗ Failed'}")
    print(f"Report: {'✓ Success' if report_success else '✗ Failed'}")
    print("="*70)
    print(f"\nCompleted: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("\nOutput files:")
    print("- Raw data: ../data/delhi_fraud_acquittals_detailed.json")
    print("- Analysis: ../data/delhi_fraud_acquittals_analysis.json")
    print("- Report: ../data/delhi_fraud_acquittals_analysis.md")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
